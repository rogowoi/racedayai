{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a762858",
   "metadata": {},
   "source": [
    "# Notebook 06 — Ensemble & Stacking (Per-Distance)\n",
    "**RaceDayAI ML Prediction Engine (Plan 07)**\n",
    "\n",
    "Per-distance meta-learners that combine supervised (NB03), Bayesian (NB04), and neural (NB05)\n",
    "predictions. Adaptive weighting by data-richness tier. Calibration checks.\n",
    "\n",
    "**Reads:** `model_predictions_{dist}.csv`, `bayesian_predictions_{dist}.csv`,\n",
    "`neural_predictions_{dist}.csv`, `athlete_profile.csv`\n",
    "**Writes:** `ensemble_predictions_70.3.csv`, `ensemble_predictions_140.6.csv`,\n",
    "`ensemble_evaluation.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ba6a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE = Path('.').resolve().parent\n",
    "CLEANED = BASE / 'data' / 'cleaned'\n",
    "\n",
    "MODEL_DISTANCES = ['70.3', '140.6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a58fe",
   "metadata": {},
   "source": [
    "## 1. Load All Model Predictions (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0088d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading 70.3 ---\n",
      "  Supervised: 204,598\n",
      "  Bayesian: 2,197,121\n",
      "  Neural: 2,197,121\n",
      "\n",
      "--- Loading 140.6 ---\n",
      "  Supervised: 230,464\n",
      "  Bayesian: 1,541,692\n",
      "  Neural: 1,541,692\n",
      "\n",
      "Profiles: 1,629,366\n"
     ]
    }
   ],
   "source": [
    "dist_data = {}\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    print(f\"\\n--- Loading {DIST} ---\")\n",
    "    data = {}\n",
    "\n",
    "    # Supervised predictions (from NB03)\n",
    "    try:\n",
    "        sup = pd.read_csv(CLEANED / f'model_predictions_{DIST}.csv', low_memory=False)\n",
    "        data['sup'] = sup\n",
    "        print(f\"  Supervised: {len(sup):,}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ⚠ model_predictions_{DIST}.csv not found\")\n",
    "        continue\n",
    "\n",
    "    # Bayesian predictions (from NB04)\n",
    "    try:\n",
    "        bayes = pd.read_csv(CLEANED / f'bayesian_predictions_{DIST}.csv', low_memory=False)\n",
    "        data['bayes'] = bayes\n",
    "        print(f\"  Bayesian: {len(bayes):,}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  ⚠ bayesian_predictions_{DIST}.csv not found — will skip Bayesian features\")\n",
    "\n",
    "    # Neural predictions (from NB05)\n",
    "    try:\n",
    "        neural = pd.read_csv(CLEANED / f'neural_predictions_{DIST}.csv', low_memory=False)\n",
    "        data['neural'] = neural\n",
    "        print(f\"  Neural: {len(neural):,}\")\n",
    "    except FileNotFoundError:\n",
    "        # Fallback: try combined file\n",
    "        try:\n",
    "            neural_all = pd.read_csv(CLEANED / 'neural_predictions.csv', low_memory=False)\n",
    "            neural = neural_all[neural_all['event_distance'] == DIST].copy()\n",
    "            data['neural'] = neural\n",
    "            print(f\"  Neural (from combined): {len(neural):,}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  ⚠ neural_predictions not found — will skip Neural features\")\n",
    "\n",
    "    dist_data[DIST] = data\n",
    "\n",
    "# Athlete profiles for data-richness features\n",
    "profiles = pd.read_csv(CLEANED / 'athlete_profile.csv',\n",
    "                        usecols=['athlete_hash', 'total_races', 'consistency_cv'],\n",
    "                        low_memory=False)\n",
    "print(f\"\\nProfiles: {len(profiles):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3bf88d",
   "metadata": {},
   "source": [
    "## 2. Build Meta-Feature Matrix (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7918a847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  META-FEATURES: 70.3\n",
      "======================================================================\n",
      "  + Bayesian: 204,598 matched\n",
      "  + Neural: 204,598 matched\n",
      "  Meta-feature matrix: 204,598 rows\n",
      "  Columns: ['athlete_hash', 'event_distance', 'event_year', 'total_sec', 'pred_xgb', 'pred_lgb', 'pred_cat', 'pred_rf', 'pred_ridge', 'pred_xgb_tuned', 'q05', 'q25', 'q50', 'q75', 'q95', 'bayes_pred', 'bayes_std', 'neural_pred', 'total_races', 'consistency_cv', 'quantile_iqr', 'n_prior_races', 'input_confidence']\n",
      "\n",
      "======================================================================\n",
      "  META-FEATURES: 140.6\n",
      "======================================================================\n",
      "  + Bayesian: 230,464 matched\n",
      "  + Neural: 230,464 matched\n",
      "  Meta-feature matrix: 230,464 rows\n",
      "  Columns: ['athlete_hash', 'event_distance', 'event_year', 'total_sec', 'pred_xgb', 'pred_lgb', 'pred_cat', 'pred_rf', 'pred_ridge', 'pred_xgb_tuned', 'q05', 'q25', 'q50', 'q75', 'q95', 'bayes_pred', 'bayes_std', 'neural_pred', 'total_races', 'consistency_cv', 'quantile_iqr', 'n_prior_races', 'input_confidence']\n"
     ]
    }
   ],
   "source": [
    "meta_dfs = {}\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in dist_data or 'sup' not in dist_data[DIST]:\n",
    "        continue\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  META-FEATURES: {DIST}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    data = dist_data[DIST]\n",
    "    meta = data['sup'].copy()\n",
    "\n",
    "    # Merge Bayesian\n",
    "    if 'bayes' in data:\n",
    "        b = data['bayes'][['athlete_hash', 'event_year', 'bayes_pred', 'bayes_std']].copy()\n",
    "        # Deduplicate if needed\n",
    "        b = b.drop_duplicates(subset=['athlete_hash', 'event_year'])\n",
    "        if 'event_year' in meta.columns and 'event_year' in b.columns:\n",
    "            meta = meta.merge(b, on=['athlete_hash', 'event_year'], how='left')\n",
    "        else:\n",
    "            meta = meta.merge(b, on='athlete_hash', how='left')\n",
    "        print(f\"  + Bayesian: {meta['bayes_pred'].notna().sum():,} matched\")\n",
    "\n",
    "    # Merge Neural\n",
    "    if 'neural' in data:\n",
    "        n = data['neural'][['athlete_hash', 'neural_pred']].drop_duplicates(subset='athlete_hash')\n",
    "        meta = meta.merge(n, on='athlete_hash', how='left')\n",
    "        print(f\"  + Neural: {meta['neural_pred'].notna().sum():,} matched\")\n",
    "\n",
    "    # Merge profile features\n",
    "    meta = meta.merge(profiles, on='athlete_hash', how='left')\n",
    "\n",
    "    # Compute IQR from quantile columns if present\n",
    "    if 'q25' in meta.columns and 'q75' in meta.columns:\n",
    "        meta['quantile_iqr'] = meta['q75'] - meta['q25']\n",
    "\n",
    "    # Data richness\n",
    "    meta['n_prior_races'] = meta['total_races'].fillna(0)\n",
    "    meta['input_confidence'] = pd.cut(meta['n_prior_races'],\n",
    "                                       bins=[-1, 0, 2, 5, 100],\n",
    "                                       labels=[0, 1, 2, 3]).astype(float)\n",
    "\n",
    "    meta_dfs[DIST] = meta\n",
    "    print(f\"  Meta-feature matrix: {len(meta):,} rows\")\n",
    "    print(f\"  Columns: {list(meta.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43b175c",
   "metadata": {},
   "source": [
    "## 3. Define Meta-Features (Per Distance)\n",
    "\n",
    "The stacking meta-model sees individual model predictions as features, plus data-richness signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e880e998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "70.3 meta-features (13):\n",
      "  pred_xgb: mean=21203.2  std=3077.5\n",
      "  pred_lgb: mean=21203.5  std=3055.5\n",
      "  pred_cat: mean=21204.9  std=3053.2\n",
      "  pred_rf: mean=21201.5  std=3049.8\n",
      "  pred_ridge: mean=21024.7  std=2531.7\n",
      "  pred_xgb_tuned: mean=21205.6  std=3115.5\n",
      "  bayes_pred: mean=21155.9  std=2514.1\n",
      "  bayes_std: mean=2581.8  std=0.0\n",
      "  neural_pred: mean=21324.0  std=2675.7\n",
      "  q50: mean=21007.9  std=2986.1\n",
      "  quantile_iqr: mean=1434.1  std=1345.6\n",
      "  n_prior_races: mean=4.9  std=6.1\n",
      "  input_confidence: mean=1.8  std=0.8\n",
      "\n",
      "140.6 meta-features (13):\n",
      "  pred_xgb: mean=44097.8  std=5871.0\n",
      "  pred_lgb: mean=44098.4  std=5823.5\n",
      "  pred_cat: mean=44100.2  std=5814.7\n",
      "  pred_rf: mean=44096.4  std=5786.9\n",
      "  pred_ridge: mean=44116.7  std=5168.1\n",
      "  pred_xgb_tuned: mean=44101.4  std=5896.6\n",
      "  bayes_pred: mean=44132.9  std=4550.0\n",
      "  bayes_std: mean=4335.1  std=0.0\n",
      "  neural_pred: mean=44222.8  std=5181.4\n",
      "  q50: mean=43924.9  std=5651.5\n",
      "  quantile_iqr: mean=2576.6  std=2545.2\n",
      "  n_prior_races: mean=4.4  std=6.5\n",
      "  input_confidence: mean=1.7  std=0.8\n"
     ]
    }
   ],
   "source": [
    "meta_features_by_dist = {}\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in meta_dfs:\n",
    "        continue\n",
    "    meta = meta_dfs[DIST]\n",
    "\n",
    "    pred_cols = []\n",
    "    # Supervised model predictions\n",
    "    for col in ['pred_xgb', 'pred_lgb', 'pred_cat', 'pred_rf', 'pred_ridge',\n",
    "                'pred_xgb_tuned', 'pred_chained']:\n",
    "        if col in meta.columns and meta[col].notna().sum() > 100:\n",
    "            pred_cols.append(col)\n",
    "\n",
    "    # Bayesian\n",
    "    if 'bayes_pred' in meta.columns and meta['bayes_pred'].notna().sum() > 100:\n",
    "        pred_cols.append('bayes_pred')\n",
    "    if 'bayes_std' in meta.columns and meta['bayes_std'].notna().sum() > 100:\n",
    "        pred_cols.append('bayes_std')\n",
    "\n",
    "    # Neural\n",
    "    if 'neural_pred' in meta.columns and meta['neural_pred'].notna().sum() > 100:\n",
    "        pred_cols.append('neural_pred')\n",
    "\n",
    "    # Quantile features\n",
    "    if 'q50' in meta.columns:\n",
    "        pred_cols.append('q50')\n",
    "    if 'quantile_iqr' in meta.columns:\n",
    "        pred_cols.append('quantile_iqr')\n",
    "\n",
    "    # Data richness\n",
    "    pred_cols.extend(['n_prior_races', 'input_confidence'])\n",
    "\n",
    "    # Fill NaN\n",
    "    for col in pred_cols:\n",
    "        if meta[col].isna().any():\n",
    "            meta[col] = meta[col].fillna(meta[col].median())\n",
    "\n",
    "    meta_features_by_dist[DIST] = pred_cols\n",
    "    print(f\"\\n{DIST} meta-features ({len(pred_cols)}):\")\n",
    "    for col in pred_cols:\n",
    "        print(f\"  {col}: mean={meta[col].mean():.1f}  std={meta[col].std():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5087dd",
   "metadata": {},
   "source": [
    "## 4. Train Meta-Learners (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed9d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  META-LEARNER: 70.3\n",
      "======================================================================\n",
      "  Meta-train: 102,337 | Meta-test: 102,261\n",
      "\n",
      "  Ridge: MAE=12.1min  R²=0.8606\n",
      "    Weights:\n",
      "      pred_xgb            : -671.3576\n",
      "      pred_lgb            : 154.4814\n",
      "      pred_cat            : 399.8085\n",
      "      pred_rf             : 272.7131\n",
      "      pred_ridge          : -2.0391\n",
      "      pred_xgb_tuned      : 3018.9578\n",
      "      bayes_pred          : -36.5237\n",
      "      bayes_std           : 0.0000\n",
      "      neural_pred         : 450.4011\n",
      "      q50                 : -427.6430\n",
      "      quantile_iqr        : 10.0300\n",
      "      n_prior_races       : -37.7927\n",
      "      input_confidence    : 6.7283\n",
      "  LightGBM: MAE=12.0min  R²=0.8613\n",
      "    Feature importance:\n",
      "      pred_xgb_tuned      : 611\n",
      "      neural_pred         : 445\n",
      "      quantile_iqr        : 252\n",
      "      pred_rf             : 225\n",
      "      bayes_pred          : 216\n",
      "      n_prior_races       : 199\n",
      "      pred_ridge          : 193\n",
      "      q50                 : 172\n",
      "      pred_xgb            : 139\n",
      "      pred_cat            : 96\n",
      "      pred_lgb            : 89\n",
      "      bayes_std           : 0\n",
      "      input_confidence    : 0\n",
      "\n",
      "  Best meta-learner: lgb (MAE=12.0min)\n",
      "\n",
      "======================================================================\n",
      "  META-LEARNER: 140.6\n",
      "======================================================================\n",
      "  Meta-train: 114,469 | Meta-test: 115,995\n",
      "\n",
      "  Ridge: MAE=19.8min  R²=0.8933\n",
      "    Weights:\n",
      "      pred_xgb            : -1.3166\n",
      "      pred_lgb            : 205.5320\n",
      "      pred_cat            : 476.7122\n",
      "      pred_rf             : -585.3773\n",
      "      pred_ridge          : -11.5488\n",
      "      pred_xgb_tuned      : 5829.5264\n",
      "      bayes_pred          : 1.7712\n",
      "      bayes_std           : 0.0000\n",
      "      neural_pred         : 664.3743\n",
      "      q50                 : -612.9509\n",
      "      quantile_iqr        : -24.6241\n",
      "      n_prior_races       : -42.7811\n",
      "      input_confidence    : 24.7547\n",
      "  LightGBM: MAE=20.0min  R²=0.8929\n",
      "    Feature importance:\n",
      "      pred_xgb_tuned      : 682\n",
      "      neural_pred         : 495\n",
      "      pred_rf             : 228\n",
      "      bayes_pred          : 193\n",
      "      q50                 : 188\n",
      "      pred_xgb            : 180\n",
      "      quantile_iqr        : 176\n",
      "      n_prior_races       : 163\n",
      "      pred_ridge          : 145\n",
      "      pred_cat            : 98\n",
      "      pred_lgb            : 93\n",
      "      input_confidence    : 5\n",
      "      bayes_std           : 0\n",
      "\n",
      "  Best meta-learner: ridge (MAE=19.8min)\n"
     ]
    }
   ],
   "source": [
    "ensemble_results = {}\n",
    "best_models = {}\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in meta_dfs or DIST not in meta_features_by_dist:\n",
    "        continue\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  META-LEARNER: {DIST}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    meta = meta_dfs[DIST]\n",
    "    META_FEATURES = meta_features_by_dist[DIST]\n",
    "\n",
    "    # Random split for meta-learner (grouped by athlete)\n",
    "    meta_athletes = meta['athlete_hash'].unique()\n",
    "    rng = np.random.RandomState(42)\n",
    "    rng.shuffle(meta_athletes)\n",
    "    split_idx = len(meta_athletes) // 2\n",
    "    train_ath = set(meta_athletes[:split_idx])\n",
    "    meta_train = meta[meta['athlete_hash'].isin(train_ath)]\n",
    "    meta_test = meta[~meta['athlete_hash'].isin(train_ath)]\n",
    "\n",
    "    X_meta_train = meta_train[META_FEATURES].values\n",
    "    y_meta_train = meta_train['total_sec'].values\n",
    "    X_meta_test = meta_test[META_FEATURES].values\n",
    "    y_meta_test = meta_test['total_sec'].values\n",
    "\n",
    "    print(f\"  Meta-train: {len(meta_train):,} | Meta-test: {len(meta_test):,}\")\n",
    "\n",
    "    # Ridge meta-learner\n",
    "    scaler_meta = StandardScaler()\n",
    "    X_mt_sc = scaler_meta.fit_transform(X_meta_train)\n",
    "    X_mtest_sc = scaler_meta.transform(X_meta_test)\n",
    "\n",
    "    ridge_meta = Ridge(alpha=1.0)\n",
    "    ridge_meta.fit(X_mt_sc, y_meta_train)\n",
    "    pred_ridge_meta = ridge_meta.predict(X_mtest_sc)\n",
    "    mae_ridge = mean_absolute_error(y_meta_test, pred_ridge_meta)\n",
    "    r2_ridge = r2_score(y_meta_test, pred_ridge_meta)\n",
    "    print(f\"\\n  Ridge: MAE={mae_ridge/60:.1f}min  R²={r2_ridge:.4f}\")\n",
    "\n",
    "    # Ridge weights\n",
    "    print(\"    Weights:\")\n",
    "    for feat, w in zip(META_FEATURES, ridge_meta.coef_):\n",
    "        print(f\"      {feat:20s}: {w:.4f}\")\n",
    "\n",
    "    # LightGBM meta-learner\n",
    "    lgb_meta = lgb.LGBMRegressor(\n",
    "        n_estimators=200, max_depth=4, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        random_state=42, n_jobs=-1, verbose=-1,\n",
    "    )\n",
    "    lgb_meta.fit(X_meta_train, y_meta_train)\n",
    "    pred_lgb_meta = lgb_meta.predict(X_meta_test)\n",
    "    mae_lgb = mean_absolute_error(y_meta_test, pred_lgb_meta)\n",
    "    r2_lgb = r2_score(y_meta_test, pred_lgb_meta)\n",
    "    print(f\"  LightGBM: MAE={mae_lgb/60:.1f}min  R²={r2_lgb:.4f}\")\n",
    "\n",
    "    # LightGBM feature importance\n",
    "    fi_meta = pd.DataFrame({'feature': META_FEATURES, 'importance': lgb_meta.feature_importances_})\n",
    "    fi_meta = fi_meta.sort_values('importance', ascending=False)\n",
    "    print(\"    Feature importance:\")\n",
    "    for _, row in fi_meta.iterrows():\n",
    "        print(f\"      {row['feature']:20s}: {row['importance']:.0f}\")\n",
    "\n",
    "    # Pick best\n",
    "    best_meta = 'lgb' if mae_lgb < mae_ridge else 'ridge'\n",
    "    best_pred = pred_lgb_meta if best_meta == 'lgb' else pred_ridge_meta\n",
    "    best_mae = min(mae_lgb, mae_ridge)\n",
    "    print(f\"\\n  Best meta-learner: {best_meta} (MAE={best_mae/60:.1f}min)\")\n",
    "\n",
    "    best_models[DIST] = {\n",
    "        'type': best_meta,\n",
    "        'lgb': lgb_meta, 'ridge': ridge_meta, 'scaler': scaler_meta,\n",
    "        'meta_test': meta_test, 'y_meta_test': y_meta_test,\n",
    "        'best_pred': best_pred, 'best_mae': best_mae,\n",
    "    }\n",
    "\n",
    "    # Individual model comparisons\n",
    "    comparisons = {}\n",
    "    for col in ['pred_xgb', 'pred_lgb', 'pred_cat', 'pred_rf', 'pred_ridge',\n",
    "                'pred_xgb_tuned', 'pred_chained', 'bayes_pred', 'neural_pred']:\n",
    "        if col in meta_test.columns and meta_test[col].notna().sum() > 100:\n",
    "            mae_i = mean_absolute_error(y_meta_test, meta_test[col].values)\n",
    "            comparisons[col] = mae_i\n",
    "    comparisons[f'ensemble_{best_meta}'] = best_mae\n",
    "\n",
    "    ensemble_results[DIST] = comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da286fe0",
   "metadata": {},
   "source": [
    "## 5. Compare Ensemble vs Individual Models (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3bd97da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  70.3: ENSEMBLE vs INDIVIDUAL MODELS\n",
      "======================================================================\n",
      "  ensemble_lgb             : MAE=12.0min ← ENSEMBLE\n",
      "  pred_xgb_tuned           : MAE=12.2min\n",
      "  pred_xgb                 : MAE=12.9min\n",
      "  pred_rf                  : MAE=13.0min\n",
      "  pred_lgb                 : MAE=13.5min\n",
      "  pred_cat                 : MAE=13.6min\n",
      "  neural_pred              : MAE=18.8min\n",
      "  pred_ridge               : MAE=27.1min\n",
      "  bayes_pred               : MAE=28.3min\n",
      "  simple_average           : MAE=13.1min\n",
      "\n",
      "======================================================================\n",
      "  140.6: ENSEMBLE vs INDIVIDUAL MODELS\n",
      "======================================================================\n",
      "  ensemble_ridge           : MAE=19.8min ← ENSEMBLE\n",
      "  pred_xgb_tuned           : MAE=19.8min\n",
      "  pred_xgb                 : MAE=20.8min\n",
      "  pred_rf                  : MAE=21.7min\n",
      "  pred_lgb                 : MAE=22.0min\n",
      "  pred_cat                 : MAE=22.1min\n",
      "  neural_pred              : MAE=32.6min\n",
      "  pred_ridge               : MAE=45.1min\n",
      "  bayes_pred               : MAE=55.0min\n",
      "  simple_average           : MAE=21.3min\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in ensemble_results:\n",
    "        continue\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  {DIST}: ENSEMBLE vs INDIVIDUAL MODELS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    comparisons = ensemble_results[DIST]\n",
    "    for name, mae_val in sorted(comparisons.items(), key=lambda x: x[1]):\n",
    "        marker = \" ← ENSEMBLE\" if 'ensemble' in name else \"\"\n",
    "        print(f\"  {name:25s}: MAE={mae_val/60:.1f}min{marker}\")\n",
    "\n",
    "    # Simple average baseline\n",
    "    meta_test = best_models[DIST]['meta_test']\n",
    "    y_meta_test = best_models[DIST]['y_meta_test']\n",
    "    avg_cols = [c for c in ['pred_xgb', 'pred_lgb', 'pred_cat']\n",
    "                if c in meta_test.columns and meta_test[c].notna().sum() > 100]\n",
    "    if avg_cols:\n",
    "        simple_avg = meta_test[avg_cols].mean(axis=1).values\n",
    "        mae_avg = mean_absolute_error(y_meta_test, simple_avg)\n",
    "        print(f\"  {'simple_average':25s}: MAE={mae_avg/60:.1f}min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45133eef",
   "metadata": {},
   "source": [
    "## 6. Adaptive Weighting by Tier (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "483d3fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 70.3: Ensemble by data-richness tier ---\n",
      "  Tier 1 (1-2 races)       : n=47,178  ensemble=4.9min  best_indiv=5.4min  +10.9%\n",
      "  Tier 2 (3-5 races)       : n=27,411  ensemble=16.2min  best_indiv=17.4min  +6.9%\n",
      "  Tier 3 (5+ races)        : n=27,672  ensemble=20.1min  best_indiv=21.0min  +4.3%\n",
      "\n",
      "--- 140.6: Ensemble by data-richness tier ---\n",
      "  Tier 1 (1-2 races)       : n=60,122  ensemble=7.5min  best_indiv=8.2min  +8.5%\n",
      "  Tier 2 (3-5 races)       : n=28,683  ensemble=28.9min  best_indiv=30.2min  +4.4%\n",
      "  Tier 3 (5+ races)        : n=27,190  ensemble=37.5min  best_indiv=38.5min  +2.7%\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in best_models:\n",
    "        continue\n",
    "    print(f\"\\n--- {DIST}: Ensemble by data-richness tier ---\")\n",
    "\n",
    "    bm = best_models[DIST]\n",
    "    meta_test = bm['meta_test']\n",
    "    y_meta_test = bm['y_meta_test']\n",
    "    best_pred = bm['best_pred']\n",
    "\n",
    "    tiers = {\n",
    "        'Tier 0 (0 races)': meta_test['n_prior_races'] == 0,\n",
    "        'Tier 1 (1-2 races)': (meta_test['n_prior_races'] >= 1) & (meta_test['n_prior_races'] <= 2),\n",
    "        'Tier 2 (3-5 races)': (meta_test['n_prior_races'] >= 3) & (meta_test['n_prior_races'] <= 5),\n",
    "        'Tier 3 (5+ races)': meta_test['n_prior_races'] > 5,\n",
    "    }\n",
    "\n",
    "    for tier_name, mask in tiers.items():\n",
    "        n = mask.sum()\n",
    "        if n < 50:\n",
    "            continue\n",
    "        mae_tier = mean_absolute_error(y_meta_test[mask], best_pred[mask])\n",
    "        # Best individual for comparison\n",
    "        best_indiv = float('inf')\n",
    "        for col in ['pred_xgb', 'pred_lgb', 'pred_cat']:\n",
    "            if col in meta_test.columns and meta_test[col].notna().sum() > 100:\n",
    "                mae_i = mean_absolute_error(y_meta_test[mask], meta_test.loc[mask, col].values)\n",
    "                best_indiv = min(best_indiv, mae_i)\n",
    "        improvement = (best_indiv - mae_tier) / best_indiv * 100 if best_indiv < float('inf') else 0\n",
    "        print(f\"  {tier_name:25s}: n={n:>6,}  ensemble={mae_tier/60:.1f}min  \"\n",
    "              f\"best_indiv={best_indiv/60:.1f}min  {improvement:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84bbe6",
   "metadata": {},
   "source": [
    "## 7. Calibration Check — Quantile Coverage (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf8b205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 70.3: Quantile calibration ---\n",
      "  q05: expected=0.05  actual=0.044  ✓\n",
      "  q25: expected=0.25  actual=0.247  ✓\n",
      "  q50: expected=0.50  actual=0.500  ✓\n",
      "  q75: expected=0.75  actual=0.749  ✓\n",
      "  q95: expected=0.95  actual=0.953  ✓\n",
      "\n",
      "--- 140.6: Quantile calibration ---\n",
      "  q05: expected=0.05  actual=0.043  ✓\n",
      "  q25: expected=0.25  actual=0.249  ✓\n",
      "  q50: expected=0.50  actual=0.499  ✓\n",
      "  q75: expected=0.75  actual=0.752  ✓\n",
      "  q95: expected=0.95  actual=0.954  ✓\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in best_models:\n",
    "        continue\n",
    "    meta_test = best_models[DIST]['meta_test']\n",
    "    y_meta_test = best_models[DIST]['y_meta_test']\n",
    "\n",
    "    print(f\"\\n--- {DIST}: Quantile calibration ---\")\n",
    "    for q_val, q_col in [(5, 'q05'), (25, 'q25'), (50, 'q50'), (75, 'q75'), (95, 'q95')]:\n",
    "        if q_col in meta_test.columns:\n",
    "            coverage = (y_meta_test <= meta_test[q_col].values).mean()\n",
    "            expected = q_val / 100\n",
    "            status = '✓' if abs(coverage - expected) < 0.03 else '✗'\n",
    "            print(f\"  q{q_val:02d}: expected={expected:.2f}  actual={coverage:.3f}  {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889d83e",
   "metadata": {},
   "source": [
    "## 8. Save Outputs (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4413ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving 70.3 ---\n",
      "  ensemble_predictions_70.3.csv: 204,598\n",
      "\n",
      "--- Saving 140.6 ---\n",
      "  ensemble_predictions_140.6.csv: 230,464\n",
      "\n",
      "ensemble_evaluation.csv: 18 rows\n",
      "\n",
      "Final rankings:\n",
      "\n",
      "  70.3:\n",
      "    ensemble_lgb               MAE=12.0min\n",
      "    pred_xgb_tuned             MAE=12.2min\n",
      "    pred_xgb                   MAE=12.9min\n",
      "    pred_rf                    MAE=13.0min\n",
      "    pred_lgb                   MAE=13.5min\n",
      "    pred_cat                   MAE=13.6min\n",
      "    neural_pred                MAE=18.8min\n",
      "    pred_ridge                 MAE=27.1min\n",
      "    bayes_pred                 MAE=28.3min\n",
      "\n",
      "  140.6:\n",
      "    ensemble_ridge             MAE=19.8min\n",
      "    pred_xgb_tuned             MAE=19.8min\n",
      "    pred_xgb                   MAE=20.8min\n",
      "    pred_rf                    MAE=21.7min\n",
      "    pred_lgb                   MAE=22.0min\n",
      "    pred_cat                   MAE=22.1min\n",
      "    neural_pred                MAE=32.6min\n",
      "    pred_ridge                 MAE=45.1min\n",
      "    bayes_pred                 MAE=55.0min\n",
      "\n",
      "✅ ENSEMBLE COMPLETE (per-distance)\n"
     ]
    }
   ],
   "source": [
    "all_eval_rows = []\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in meta_dfs or DIST not in best_models:\n",
    "        continue\n",
    "    print(f\"\\n--- Saving {DIST} ---\")\n",
    "\n",
    "    meta = meta_dfs[DIST]\n",
    "    bm = best_models[DIST]\n",
    "    META_FEATURES = meta_features_by_dist[DIST]\n",
    "\n",
    "    # Generate ensemble predictions for full dataset\n",
    "    X_all = meta[META_FEATURES].values\n",
    "    if bm['type'] == 'lgb':\n",
    "        meta['ensemble_pred'] = bm['lgb'].predict(X_all)\n",
    "    else:\n",
    "        meta['ensemble_pred'] = bm['ridge'].predict(bm['scaler'].transform(X_all))\n",
    "\n",
    "    # Output columns\n",
    "    out_cols = ['athlete_hash', 'event_distance', 'total_sec', 'ensemble_pred']\n",
    "    for col in ['pred_xgb', 'pred_lgb', 'pred_xgb_tuned', 'pred_chained',\n",
    "                'bayes_pred', 'neural_pred', 'n_prior_races',\n",
    "                'q05', 'q25', 'q50', 'q75', 'q95']:\n",
    "        if col in meta.columns:\n",
    "            out_cols.append(col)\n",
    "\n",
    "    ensemble_out = meta[[c for c in out_cols if c in meta.columns]].copy()\n",
    "    fname = f'ensemble_predictions_{DIST}.csv'\n",
    "    ensemble_out.to_csv(CLEANED / fname, index=False)\n",
    "    print(f\"  {fname}: {len(ensemble_out):,}\")\n",
    "\n",
    "    # Evaluation rows\n",
    "    for model_name, mae_val in ensemble_results.get(DIST, {}).items():\n",
    "        all_eval_rows.append({'distance': DIST, 'model': model_name, 'MAE_sec': mae_val,\n",
    "                              'MAE_min': mae_val/60})\n",
    "\n",
    "# Combined evaluation summary\n",
    "if all_eval_rows:\n",
    "    eval_df = pd.DataFrame(all_eval_rows).sort_values(['distance', 'MAE_sec'])\n",
    "    eval_df.to_csv(CLEANED / 'ensemble_evaluation.csv', index=False)\n",
    "    print(f\"\\nensemble_evaluation.csv: {len(eval_df)} rows\")\n",
    "    print(f\"\\nFinal rankings:\")\n",
    "    for DIST in MODEL_DISTANCES:\n",
    "        sub = eval_df[eval_df['distance'] == DIST].head(10)\n",
    "        if len(sub) == 0:\n",
    "            continue\n",
    "        print(f\"\\n  {DIST}:\")\n",
    "        for _, row in sub.iterrows():\n",
    "            print(f\"    {row['model']:25s}  MAE={row['MAE_min']:.1f}min\")\n",
    "\n",
    "print(\"\\n✅ ENSEMBLE COMPLETE (per-distance)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
