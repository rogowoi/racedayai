{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8fc00bd",
   "metadata": {},
   "source": [
    "# Notebook 03 — Supervised Learning (Per-Distance Models)\n",
    "**RaceDayAI ML Prediction Engine (Plan 07)**\n",
    "\n",
    "Separate model suites for each race distance — 70.3 and 140.6 have fundamentally\n",
    "different distributions, fatigue dynamics, and pacing strategies.\n",
    "\n",
    "For each distance independently:\n",
    "- XGBoost / LightGBM / CatBoost / RF / Ridge comparison\n",
    "- Optuna hyperparameter tuning on best model\n",
    "- Chained model experiment (swim → bike → run)\n",
    "- Quantile regression for uncertainty bands\n",
    "\n",
    "**Reads:** `athlete_race.csv`, `athlete_profile.csv`, `cluster_assignments.csv`\n",
    "**Writes:** `model_predictions_70.3.csv`, `model_predictions_140.6.csv`,\n",
    "`quantile_predictions_70.3.csv`, `quantile_predictions_140.6.csv`,\n",
    "`feature_importance.csv`, `supervised_results.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 3.2.0, LightGBM 4.6.0, CatBoost 1.2.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc, warnings, pickle, json\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE = Path('.').resolve().parent\n",
    "CLEANED = BASE / 'data' / 'cleaned'\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "print(f\"XGBoost {xgb.__version__}, LightGBM {lgb.__version__}, CatBoost {cb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ad51d5",
   "metadata": {},
   "source": [
    "## 1. Load & Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Races: 4,124,345 | Profiles: 1,629,366 | Clusters: 301,730\n",
      "Total AG records with valid times: 4,104,829\n",
      "  70.3: 2,197,121\n",
      "  140.6: 1,541,692\n",
      "  olympic: 256,589\n",
      "  sprint: 109,427\n",
      "Loaded in 27.3s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "races = pd.read_csv(CLEANED / 'athlete_race.csv', low_memory=False)\n",
    "profiles = pd.read_csv(CLEANED / 'athlete_profile.csv', low_memory=False)\n",
    "clusters = pd.read_csv(CLEANED / 'cluster_assignments.csv', low_memory=False)\n",
    "print(f\"Races: {len(races):,} | Profiles: {len(profiles):,} | Clusters: {len(clusters):,}\")\n",
    "\n",
    "# Merge profile + cluster features onto races\n",
    "profile_cols = ['athlete_hash', 'total_races', 'pb_total_sec',\n",
    "                'swim_strength_z', 'bike_strength_z', 'run_strength_z',\n",
    "                'improvement_slope', 'consistency_cv', 'dnf_rate']\n",
    "pcols = [c for c in profile_cols if c in profiles.columns]\n",
    "df = races.merge(profiles[pcols], on='athlete_hash', how='left', suffixes=('','_prof'))\n",
    "\n",
    "cluster_cols = ['athlete_hash', 'cluster_id']\n",
    "ccols = [c for c in cluster_cols if c in clusters.columns]\n",
    "df = df.merge(clusters[ccols], on='athlete_hash', how='left')\n",
    "\n",
    "# Filter: AG athletes with valid total_sec\n",
    "df = df[df['is_pro'] != True].copy()\n",
    "df = df[df['total_sec'].notna() & (df['total_sec'] > 3600) & (df['total_sec'] < 61200)].copy()\n",
    "df['year'] = pd.to_numeric(df['event_year'], errors='coerce')\n",
    "\n",
    "print(f\"Total AG records with valid times: {len(df):,}\")\n",
    "for dist in df['event_distance'].value_counts().head(6).index:\n",
    "    n = (df['event_distance'] == dist).sum()\n",
    "    print(f\"  {dist}: {n:,}\")\n",
    "print(f\"Loaded in {time()-t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3de45d",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering (distance-agnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75bed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (13): ['gender_enc', 'age_band', 'country_enc', 'year', 'total_races', 'pb_total_sec', 'swim_strength_z', 'bike_strength_z', 'run_strength_z', 'improvement_slope', 'consistency_cv', 'dnf_rate', 'cluster_id']\n"
     ]
    }
   ],
   "source": [
    "# Encode categoricals\n",
    "le_gender = LabelEncoder()\n",
    "df['gender_enc'] = le_gender.fit_transform(df['gender'].fillna('M'))\n",
    "\n",
    "# Age band as numeric\n",
    "df['age_band'] = pd.to_numeric(df['age_group'].str.extract(r'(\\d+)', expand=False), errors='coerce')\n",
    "\n",
    "# Country frequency encoding (top 30)\n",
    "country_counts = df['country'].value_counts()\n",
    "top_countries = country_counts.head(30).index.tolist()\n",
    "df['country_enc'] = df['country'].apply(lambda x: top_countries.index(x) + 1 if x in top_countries else 0)\n",
    "\n",
    "# Cluster (fill -1 for missing)\n",
    "df['cluster_id'] = df['cluster_id'].fillna(-1).astype(int)\n",
    "\n",
    "# Features — NO distance_enc since we train per-distance\n",
    "FEATURES = [\n",
    "    'gender_enc', 'age_band', 'country_enc', 'year',\n",
    "    'total_races', 'pb_total_sec',\n",
    "    'swim_strength_z', 'bike_strength_z', 'run_strength_z',\n",
    "    'improvement_slope', 'consistency_cv', 'dnf_rate',\n",
    "    'cluster_id',\n",
    "]\n",
    "\n",
    "TARGET = 'total_sec'\n",
    "SEGMENT_TARGETS = ['swim_sec', 'bike_sec', 'run_sec']\n",
    "\n",
    "# Fill NaN features with median (per-distance fill happens later)\n",
    "for col in FEATURES:\n",
    "    if df[col].isna().any():\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "print(f\"Features ({len(FEATURES)}): {FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35116f74",
   "metadata": {},
   "source": [
    "## 3. Per-Distance Model Training\n",
    "\n",
    "Core principle: **70.3 and 140.6 are different sports.** Fade ratio, pacing strategies,\n",
    "nutrition impact, and performance distributions are fundamentally different. Training\n",
    "separate models avoids the model wasting capacity on distance discrimination and lets\n",
    "it focus on what actually drives performance within each distance.\n",
    "\n",
    "Sprint and Olympic get simpler models (less data) or are handled by scaling from 70.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bc8ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances to model separately\n",
    "MODEL_DISTANCES = ['70.3', '140.6']\n",
    "\n",
    "# Storage for all results\n",
    "all_results = {}\n",
    "all_predictions = {}\n",
    "all_quantile_preds = {}\n",
    "all_feature_importance = {}\n",
    "all_models = {}\n",
    "\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'MAE_sec': mae, 'MAE_min': mae/60, 'MAPE': mape, 'R2': r2}\n",
    "\n",
    "def print_eval(name, metrics):\n",
    "    print(f\"  {name:25s}  MAE={metrics['MAE_min']:.1f}min  MAPE={metrics['MAPE']:.3f}  R²={metrics['R2']:.4f}\")\n",
    "\n",
    "def random_athlete_split(data, train_frac=0.70, val_frac=0.15, seed=42):\n",
    "    \"\"\"Split by athlete to prevent data leakage. Same athlete stays in one split.\"\"\"\n",
    "    athletes = data['athlete_hash'].unique()\n",
    "    rng = np.random.RandomState(seed)\n",
    "    rng.shuffle(athletes)\n",
    "    n = len(athletes)\n",
    "    n_train = int(train_frac * n)\n",
    "    n_val = int(val_frac * n)\n",
    "    train_ath = set(athletes[:n_train])\n",
    "    val_ath = set(athletes[n_train:n_train + n_val])\n",
    "    test_ath = set(athletes[n_train + n_val:])\n",
    "    train = data[data['athlete_hash'].isin(train_ath)]\n",
    "    val = data[data['athlete_hash'].isin(val_ath)]\n",
    "    test = data[data['athlete_hash'].isin(test_ath)]\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af832f6d",
   "metadata": {},
   "source": [
    "### 3.1 Training Loop — Each Distance Gets Its Own Model Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38713bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  DISTANCE: 70.3\n",
      "======================================================================\n",
      "Records: 2,197,121\n",
      "Time range: 1.4h — 16.9h\n",
      "Median: 5.80h  Mean: 5.88h\n",
      "Train: 1,788,592 | Val: 203,931 | Test: 204,598\n",
      "  Ridge (val)                MAE=27.2min  MAPE=0.078  R²=0.5384\n",
      "  Ridge (test)               MAE=27.1min  MAPE=0.078  R²=0.5351\n",
      "  RandomForest (val)         MAE=13.0min  MAPE=0.038  R²=0.8345\n",
      "  RandomForest (test)        MAE=12.9min  MAPE=0.038  R²=0.8306\n",
      "  XGBoost (val)              MAE=12.9min  MAPE=0.037  R²=0.8479\n",
      "  XGBoost (test)             MAE=12.8min  MAPE=0.037  R²=0.8461\n",
      "  LightGBM (val)             MAE=13.5min  MAPE=0.039  R²=0.8383\n",
      "  LightGBM (test)            MAE=13.5min  MAPE=0.039  R²=0.8363\n",
      "  CatBoost (val)             MAE=13.6min  MAPE=0.039  R²=0.8362\n",
      "  CatBoost (test)            MAE=13.5min  MAPE=0.039  R²=0.8339\n",
      "\n",
      "  --- 70.3 Summary (test set) ---\n",
      "    XGB_test              MAE=12.8min  R²=0.8461 ← BEST\n",
      "    RF_test               MAE=12.9min  R²=0.8306\n",
      "    LGB_test              MAE=13.5min  R²=0.8363\n",
      "    CAT_test              MAE=13.5min  R²=0.8339\n",
      "    Ridge_test            MAE=27.1min  R²=0.5351\n",
      "\n",
      "======================================================================\n",
      "  DISTANCE: 140.6\n",
      "======================================================================\n",
      "Records: 1,541,692\n",
      "Time range: 1.0h — 17.0h\n",
      "Median: 12.09h  Mean: 12.25h\n",
      "Train: 1,079,733 | Val: 231,495 | Test: 230,464\n",
      "  Ridge (val)                MAE=45.2min  MAPE=0.064  R²=0.6730\n",
      "  Ridge (test)               MAE=45.3min  MAPE=0.064  R²=0.6669\n",
      "  RandomForest (val)         MAE=21.7min  MAPE=0.031  R²=0.8682\n",
      "  RandomForest (test)        MAE=21.7min  MAPE=0.031  R²=0.8669\n",
      "  XGBoost (val)              MAE=20.7min  MAPE=0.029  R²=0.8878\n",
      "  XGBoost (test)             MAE=20.7min  MAPE=0.029  R²=0.8862\n",
      "  LightGBM (val)             MAE=21.9min  MAPE=0.031  R²=0.8795\n",
      "  LightGBM (test)            MAE=21.9min  MAPE=0.031  R²=0.8776\n",
      "  CatBoost (val)             MAE=22.0min  MAPE=0.031  R²=0.8795\n",
      "  CatBoost (test)            MAE=22.0min  MAPE=0.031  R²=0.8775\n",
      "\n",
      "  --- 140.6 Summary (test set) ---\n",
      "    XGB_test              MAE=20.7min  R²=0.8862 ← BEST\n",
      "    RF_test               MAE=21.7min  R²=0.8669\n",
      "    LGB_test              MAE=21.9min  R²=0.8776\n",
      "    CAT_test              MAE=22.0min  R²=0.8775\n",
      "    Ridge_test            MAE=45.3min  R²=0.6669\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"  DISTANCE: {DIST}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Filter to this distance\n",
    "    dist_df = df[df['event_distance'] == DIST].copy()\n",
    "    dist_df = dist_df.dropna(subset=[TARGET])\n",
    "    print(f\"Records: {len(dist_df):,}\")\n",
    "    print(f\"Time range: {dist_df[TARGET].min()/3600:.1f}h — {dist_df[TARGET].max()/3600:.1f}h\")\n",
    "    print(f\"Median: {dist_df[TARGET].median()/3600:.2f}h  Mean: {dist_df[TARGET].mean()/3600:.2f}h\")\n",
    "\n",
    "    # Random split (grouped by athlete to prevent leakage)\n",
    "    train, val, test = random_athlete_split(dist_df)\n",
    "    print(f\"Train: {len(train):,} | Val: {len(val):,} | Test: {len(test):,}\")\n",
    "\n",
    "    if len(train) < 1000 or len(val) < 100 or len(test) < 100:\n",
    "        print(f\"  ⚠ Insufficient data for {DIST}, skipping\")\n",
    "        continue\n",
    "\n",
    "    X_train, y_train = train[FEATURES].values, train[TARGET].values\n",
    "    X_val, y_val = val[FEATURES].values, val[TARGET].values\n",
    "    X_test, y_test = test[FEATURES].values, test[TARGET].values\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # ── Ridge ──\n",
    "    scaler_r = StandardScaler()\n",
    "    X_tr_sc = scaler_r.fit_transform(X_train)\n",
    "    X_v_sc = scaler_r.transform(X_val)\n",
    "    X_te_sc = scaler_r.transform(X_test)\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    ridge.fit(X_tr_sc, y_train)\n",
    "    results['Ridge_val'] = evaluate('Ridge', y_val, ridge.predict(X_v_sc))\n",
    "    results['Ridge_test'] = evaluate('Ridge', y_test, ridge.predict(X_te_sc))\n",
    "    print_eval('Ridge (val)', results['Ridge_val'])\n",
    "    print_eval('Ridge (test)', results['Ridge_test'])\n",
    "\n",
    "    # ── Random Forest ──\n",
    "    rf = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_leaf=20,\n",
    "                               n_jobs=-1, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    results['RF_val'] = evaluate('RF', y_val, rf.predict(X_val))\n",
    "    results['RF_test'] = evaluate('RF', y_test, rf.predict(X_test))\n",
    "    print_eval('RandomForest (val)', results['RF_val'])\n",
    "    print_eval('RandomForest (test)', results['RF_test'])\n",
    "\n",
    "    # ── XGBoost ──\n",
    "    xgb_m = xgb.XGBRegressor(\n",
    "        n_estimators=500, max_depth=8, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        min_child_weight=50, reg_alpha=0.1, reg_lambda=1.0,\n",
    "        tree_method='hist', random_state=42, n_jobs=-1,\n",
    "    )\n",
    "    xgb_m.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "    pred_xgb_val = xgb_m.predict(X_val)\n",
    "    pred_xgb_test = xgb_m.predict(X_test)\n",
    "    results['XGB_val'] = evaluate('XGBoost', y_val, pred_xgb_val)\n",
    "    results['XGB_test'] = evaluate('XGBoost', y_test, pred_xgb_test)\n",
    "    print_eval('XGBoost (val)', results['XGB_val'])\n",
    "    print_eval('XGBoost (test)', results['XGB_test'])\n",
    "\n",
    "    # ── LightGBM ──\n",
    "    lgb_m = lgb.LGBMRegressor(\n",
    "        n_estimators=500, max_depth=8, learning_rate=0.05,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        min_child_samples=50, reg_alpha=0.1, reg_lambda=1.0,\n",
    "        random_state=42, n_jobs=-1, verbose=-1,\n",
    "    )\n",
    "    lgb_m.fit(X_train, y_train, eval_set=[(X_val, y_val)],\n",
    "              callbacks=[lgb.log_evaluation(0)])\n",
    "    pred_lgb_val = lgb_m.predict(X_val)\n",
    "    pred_lgb_test = lgb_m.predict(X_test)\n",
    "    results['LGB_val'] = evaluate('LightGBM', y_val, pred_lgb_val)\n",
    "    results['LGB_test'] = evaluate('LightGBM', y_test, pred_lgb_test)\n",
    "    print_eval('LightGBM (val)', results['LGB_val'])\n",
    "    print_eval('LightGBM (test)', results['LGB_test'])\n",
    "\n",
    "    # ── CatBoost ──\n",
    "    cat_m = cb.CatBoostRegressor(\n",
    "        iterations=500, depth=8, learning_rate=0.05,\n",
    "        subsample=0.8, l2_leaf_reg=3.0,\n",
    "        random_seed=42, verbose=0,\n",
    "    )\n",
    "    cat_m.fit(X_train, y_train, eval_set=(X_val, y_val))\n",
    "    pred_cat_val = cat_m.predict(X_val)\n",
    "    pred_cat_test = cat_m.predict(X_test)\n",
    "    results['CAT_val'] = evaluate('CatBoost', y_val, pred_cat_val)\n",
    "    results['CAT_test'] = evaluate('CatBoost', y_test, pred_cat_test)\n",
    "    print_eval('CatBoost (val)', results['CAT_val'])\n",
    "    print_eval('CatBoost (test)', results['CAT_test'])\n",
    "\n",
    "    # ── Summary for this distance ──\n",
    "    print(f\"\\n  --- {DIST} Summary (test set) ---\")\n",
    "    test_results = {k: v for k, v in results.items() if 'test' in k}\n",
    "    best = min(test_results, key=lambda k: test_results[k]['MAE_sec'])\n",
    "    for k, v in sorted(test_results.items(), key=lambda x: x[1]['MAE_sec']):\n",
    "        marker = ' ← BEST' if k == best else ''\n",
    "        print(f\"    {k:20s}  MAE={v['MAE_min']:.1f}min  R²={v['R2']:.4f}{marker}\")\n",
    "\n",
    "    # Store\n",
    "    all_results[DIST] = results\n",
    "    all_models[DIST] = {\n",
    "        'xgb': xgb_m, 'lgb': lgb_m, 'cat': cat_m, 'rf': rf, 'ridge': ridge,\n",
    "        'scaler': scaler_r,\n",
    "    }\n",
    "\n",
    "    # Store test predictions\n",
    "    all_predictions[DIST] = {\n",
    "        'test_df': test,\n",
    "        'y_test': y_test,\n",
    "        'pred_xgb': pred_xgb_test,\n",
    "        'pred_lgb': pred_lgb_test,\n",
    "        'pred_cat': pred_cat_test,\n",
    "        'pred_rf': rf.predict(X_test),\n",
    "        'pred_ridge': ridge.predict(X_te_sc),\n",
    "    }\n",
    "\n",
    "    # Feature importance\n",
    "    all_feature_importance[DIST] = pd.DataFrame({\n",
    "        'feature': FEATURES,\n",
    "        'xgb_importance': xgb_m.feature_importances_,\n",
    "        'lgb_importance': lgb_m.feature_importances_,\n",
    "    }).sort_values('xgb_importance', ascending=False)\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c722e",
   "metadata": {},
   "source": [
    "## 4. Optuna Tuning (Per Distance, Best Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f46047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  OPTUNA TUNING: 70.3\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7055018282334402a3bb77ad5bbc0360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best trial MAE: 24.1min\n",
      "  XGB-Tuned 70.3 (test)      MAE=12.2min  MAPE=0.035  R²=0.8574\n",
      "\n",
      "======================================================================\n",
      "  OPTUNA TUNING: 140.6\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9ac2d4870d4d9fa043b24fd539ab71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best trial MAE: 20.7min\n",
      "  XGB-Tuned 140.6 (test)     MAE=19.8min  MAPE=0.028  R²=0.8914\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in all_models:\n",
    "        continue\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  OPTUNA TUNING: {DIST}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    dist_df = df[df['event_distance'] == DIST].dropna(subset=[TARGET])\n",
    "    train, val, test = random_athlete_split(dist_df)\n",
    "\n",
    "    X_train, y_train = train[FEATURES].values, train[TARGET].values\n",
    "    X_val, y_val = val[FEATURES].values, val[TARGET].values\n",
    "    X_test, y_test = test[FEATURES].values, test[TARGET].values\n",
    "\n",
    "    # Subsample for speed\n",
    "    n_tune = min(300000, len(X_train))\n",
    "    tidx = np.random.RandomState(42).choice(len(X_train), n_tune, replace=False)\n",
    "    X_tune, y_tune = X_train[tidx], y_train[tidx]\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_estimators': 500,\n",
    "            'max_depth': trial.suggest_int('max_depth', 4, 12),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 10, 200),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10, log=True),\n",
    "            'tree_method': 'hist', 'random_state': 42, 'n_jobs': -1,\n",
    "        }\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        split = int(0.8 * len(X_tune))\n",
    "        model.fit(X_tune[:split], y_tune[:split],\n",
    "                  eval_set=[(X_tune[split:], y_tune[split:])], verbose=0)\n",
    "        return mean_absolute_error(y_tune[split:], model.predict(X_tune[split:]))\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "    print(f\"  Best trial MAE: {study.best_value/60:.1f}min\")\n",
    "\n",
    "    # Retrain with best params\n",
    "    bp = study.best_params\n",
    "    bp.update({'n_estimators': 800, 'tree_method': 'hist', 'random_state': 42, 'n_jobs': -1})\n",
    "    xgb_tuned = xgb.XGBRegressor(**bp)\n",
    "    xgb_tuned.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "\n",
    "    pred_tuned_test = xgb_tuned.predict(X_test)\n",
    "    metrics = evaluate('XGB-Tuned', y_test, pred_tuned_test)\n",
    "    print_eval(f'XGB-Tuned {DIST} (test)', metrics)\n",
    "\n",
    "    all_results[DIST]['XGB_Tuned_test'] = metrics\n",
    "    all_models[DIST]['xgb_tuned'] = xgb_tuned\n",
    "    all_predictions[DIST]['pred_xgb_tuned'] = pred_tuned_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e250747",
   "metadata": {},
   "source": [
    "## 5. Chained Models (Per Distance)\n",
    "\n",
    "Swim → Bike → Run sequential prediction. Bike model receives swim prediction as input.\n",
    "Run model receives swim + bike predictions as fatigue carry-through signals.\n",
    "This captures real fatigue dynamics that differ between 70.3 and 140.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb90311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  CHAINED MODELS: 70.3\n",
      "======================================================================\n",
      "  Segment-complete: train=1,750,200 val=197,092 test=196,261\n",
      "  --- Swim ---\n",
      "  Swim (val)                 MAE=2.6min  MAPE=0.071  R²=0.7627\n",
      "  --- Bike (+swim_pred) ---\n",
      "  Bike-chained (val)         MAE=7.6min  MAPE=0.044  R²=0.7880\n",
      "  --- Run (+swim_pred +bike_pred) ---\n",
      "  Run-chained (val)          MAE=6.9min  MAPE=0.055  R²=0.8331\n",
      "  Chained-Total 70.3 (val)   MAE=16.1min  MAPE=0.045  R²=0.8167\n",
      "  Chained-Total 70.3 (test)  MAE=16.1min  MAPE=0.045  R²=0.8198\n",
      "\n",
      "======================================================================\n",
      "  CHAINED MODELS: 140.6\n",
      "======================================================================\n",
      "  Segment-complete: train=1,042,237 val=222,465 test=224,412\n",
      "  --- Swim ---\n",
      "  Swim (val)                 MAE=3.4min  MAPE=0.051  R²=0.8206\n",
      "  --- Bike (+swim_pred) ---\n",
      "  Bike-chained (val)         MAE=11.6min  MAPE=0.032  R²=0.8481\n",
      "  --- Run (+swim_pred +bike_pred) ---\n",
      "  Run-chained (val)          MAE=12.3min  MAPE=0.045  R²=0.8537\n",
      "  Chained-Total 140.6 (val)  MAE=26.8min  MAPE=0.036  R²=0.8662\n",
      "  Chained-Total 140.6 (test)  MAE=27.0min  MAPE=0.037  R²=0.8655\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in all_models:\n",
    "        continue\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  CHAINED MODELS: {DIST}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    dist_df = df[(df['event_distance'] == DIST)].dropna(subset=SEGMENT_TARGETS + [TARGET])\n",
    "    train, val, test = random_athlete_split(dist_df)\n",
    "    print(f\"  Segment-complete: train={len(train):,} val={len(val):,} test={len(test):,}\")\n",
    "\n",
    "    if len(train) < 1000:\n",
    "        print(f\"  ⚠ Insufficient segment data for {DIST}\")\n",
    "        continue\n",
    "\n",
    "    # SWIM\n",
    "    print(\"  --- Swim ---\")\n",
    "    xgb_s = xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.05,\n",
    "                               tree_method='hist', random_state=42, n_jobs=-1, verbosity=0)\n",
    "    xgb_s.fit(train[FEATURES].values, train['swim_sec'].values)\n",
    "    ps_val = xgb_s.predict(val[FEATURES].values)\n",
    "    ps_test = xgb_s.predict(test[FEATURES].values)\n",
    "    m = evaluate('Swim', val['swim_sec'].values, ps_val)\n",
    "    print_eval('Swim (val)', m)\n",
    "\n",
    "    # BIKE — swim_pred as extra feature\n",
    "    print(\"  --- Bike (+swim_pred) ---\")\n",
    "    FEAT_B = FEATURES + ['swim_pred']\n",
    "    for split_data, pred_swim in [(train, xgb_s.predict(train[FEATURES].values)),\n",
    "                                   (val, ps_val), (test, ps_test)]:\n",
    "        split_data = split_data.copy()\n",
    "        split_data['swim_pred'] = pred_swim\n",
    "\n",
    "    train_b = train.copy(); train_b['swim_pred'] = xgb_s.predict(train[FEATURES].values)\n",
    "    val_b = val.copy(); val_b['swim_pred'] = ps_val\n",
    "    test_b = test.copy(); test_b['swim_pred'] = ps_test\n",
    "\n",
    "    xgb_b = xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.05,\n",
    "                               tree_method='hist', random_state=42, n_jobs=-1, verbosity=0)\n",
    "    xgb_b.fit(train_b[FEAT_B].values, train['bike_sec'].values)\n",
    "    pb_val = xgb_b.predict(val_b[FEAT_B].values)\n",
    "    pb_test = xgb_b.predict(test_b[FEAT_B].values)\n",
    "    m = evaluate('Bike', val['bike_sec'].values, pb_val)\n",
    "    print_eval('Bike-chained (val)', m)\n",
    "\n",
    "    # RUN — swim_pred + bike_pred as extra features\n",
    "    print(\"  --- Run (+swim_pred +bike_pred) ---\")\n",
    "    FEAT_R = FEATURES + ['swim_pred', 'bike_pred']\n",
    "    train_r = train_b.copy(); train_r['bike_pred'] = xgb_b.predict(train_b[FEAT_B].values)\n",
    "    val_r = val_b.copy(); val_r['bike_pred'] = pb_val\n",
    "    test_r = test_b.copy(); test_r['bike_pred'] = pb_test\n",
    "\n",
    "    xgb_r = xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.05,\n",
    "                               tree_method='hist', random_state=42, n_jobs=-1, verbosity=0)\n",
    "    xgb_r.fit(train_r[FEAT_R].values, train['run_sec'].values)\n",
    "    pr_val = xgb_r.predict(val_r[FEAT_R].values)\n",
    "    pr_test = xgb_r.predict(test_r[FEAT_R].values)\n",
    "    m = evaluate('Run', val['run_sec'].values, pr_val)\n",
    "    print_eval('Run-chained (val)', m)\n",
    "\n",
    "    # CHAINED TOTAL\n",
    "    chained_val = ps_val + pb_val + pr_val\n",
    "    chained_test = ps_test + pb_test + pr_test\n",
    "    m_val = evaluate('Chained', val['total_sec'].values, chained_val)\n",
    "    m_test = evaluate('Chained', test['total_sec'].values, chained_test)\n",
    "    print_eval(f'Chained-Total {DIST} (val)', m_val)\n",
    "    print_eval(f'Chained-Total {DIST} (test)', m_test)\n",
    "\n",
    "    all_results[DIST]['Chained_val'] = m_val\n",
    "    all_results[DIST]['Chained_test'] = m_test\n",
    "    all_predictions[DIST]['pred_chained'] = chained_test\n",
    "    all_predictions[DIST]['pred_swim'] = ps_test\n",
    "    all_predictions[DIST]['pred_bike'] = pb_test\n",
    "    all_predictions[DIST]['pred_run'] = pr_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d83e664",
   "metadata": {},
   "source": [
    "## 6. Quantile Regression (Per Distance)\n",
    "\n",
    "Separate quantile models per distance — uncertainty bands are narrower for 70.3 than 140.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4081c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Quantile Regression: 70.3 ---\n",
      "  Quantile calibration (70.3, val):\n",
      "    q=0.05: expected=0.05  actual=0.043  ✓\n",
      "    q=0.25: expected=0.25  actual=0.247  ✓\n",
      "    q=0.50: expected=0.50  actual=0.498  ✓\n",
      "    q=0.75: expected=0.75  actual=0.749  ✓\n",
      "    q=0.95: expected=0.95  actual=0.954  ✓\n",
      "  Median IQR: 22.3min  Mean IQR: 23.9min\n",
      "\n",
      "--- Quantile Regression: 140.6 ---\n",
      "  Quantile calibration (140.6, val):\n",
      "    q=0.05: expected=0.05  actual=0.044  ✓\n",
      "    q=0.25: expected=0.25  actual=0.248  ✓\n",
      "    q=0.50: expected=0.50  actual=0.500  ✓\n",
      "    q=0.75: expected=0.75  actual=0.752  ✓\n",
      "    q=0.95: expected=0.95  actual=0.955  ✓\n",
      "  Median IQR: 36.7min  Mean IQR: 42.9min\n"
     ]
    }
   ],
   "source": [
    "quantiles = [0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in all_models:\n",
    "        continue\n",
    "    print(f\"\\n--- Quantile Regression: {DIST} ---\")\n",
    "\n",
    "    dist_df = df[df['event_distance'] == DIST].dropna(subset=[TARGET])\n",
    "    train, val, test = random_athlete_split(dist_df)\n",
    "\n",
    "    X_train, y_train = train[FEATURES].values, train[TARGET].values\n",
    "    X_val, y_val = val[FEATURES].values, val[TARGET].values\n",
    "    X_test, y_test = test[FEATURES].values, test[TARGET].values\n",
    "\n",
    "    q_preds_test = {}\n",
    "    q_preds_val = {}\n",
    "\n",
    "    for q in quantiles:\n",
    "        qm = lgb.LGBMRegressor(\n",
    "            n_estimators=300, max_depth=8, learning_rate=0.05,\n",
    "            objective='quantile', alpha=q,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            random_state=42, n_jobs=-1, verbose=-1,\n",
    "        )\n",
    "        qm.fit(X_train, y_train)\n",
    "        q_preds_val[q] = qm.predict(X_val)\n",
    "        q_preds_test[q] = qm.predict(X_test)\n",
    "\n",
    "    # Calibration check\n",
    "    print(f\"  Quantile calibration ({DIST}, val):\")\n",
    "    for q in quantiles:\n",
    "        coverage = (y_val <= q_preds_val[q]).mean()\n",
    "        status = '✓' if abs(coverage - q) < 0.03 else '✗'\n",
    "        print(f\"    q={q:.2f}: expected={q:.2f}  actual={coverage:.3f}  {status}\")\n",
    "\n",
    "    iqr = q_preds_test[0.75] - q_preds_test[0.25]\n",
    "    print(f\"  Median IQR: {np.median(iqr)/60:.1f}min  Mean IQR: {np.mean(iqr)/60:.1f}min\")\n",
    "\n",
    "    all_quantile_preds[DIST] = q_preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880ce22a",
   "metadata": {},
   "source": [
    "## 7. Feature Importance (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4befe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Importance: 70.3 ---\n",
      "  pb_total_sec               xgb=0.3830  lgb=2633.0000\n",
      "  gender_enc                 xgb=0.2452  lgb=295.0000\n",
      "  age_band                   xgb=0.1035  lgb=914.0000\n",
      "  cluster_id                 xgb=0.0694  lgb=500.0000\n",
      "  run_strength_z             xgb=0.0471  lgb=981.0000\n",
      "  total_races                xgb=0.0339  lgb=1429.0000\n",
      "  country_enc                xgb=0.0334  lgb=1381.0000\n",
      "  bike_strength_z            xgb=0.0230  lgb=1274.0000\n",
      "  consistency_cv             xgb=0.0220  lgb=2145.0000\n",
      "  year                       xgb=0.0173  lgb=1998.0000\n",
      "  swim_strength_z            xgb=0.0156  lgb=626.0000\n",
      "  improvement_slope          xgb=0.0067  lgb=824.0000\n",
      "  dnf_rate                   xgb=0.0000  lgb=0.0000\n",
      "\n",
      "--- Feature Importance: 140.6 ---\n",
      "  pb_total_sec               xgb=0.4743  lgb=2685.0000\n",
      "  run_strength_z             xgb=0.1385  lgb=1349.0000\n",
      "  cluster_id                 xgb=0.1039  lgb=543.0000\n",
      "  gender_enc                 xgb=0.0770  lgb=302.0000\n",
      "  consistency_cv             xgb=0.0533  lgb=2545.0000\n",
      "  total_races                xgb=0.0403  lgb=1411.0000\n",
      "  bike_strength_z            xgb=0.0382  lgb=1721.0000\n",
      "  age_band                   xgb=0.0354  lgb=744.0000\n",
      "  year                       xgb=0.0129  lgb=1639.0000\n",
      "  improvement_slope          xgb=0.0086  lgb=1006.0000\n",
      "  country_enc                xgb=0.0082  lgb=566.0000\n",
      "  swim_strength_z            xgb=0.0078  lgb=485.0000\n",
      "  dnf_rate                   xgb=0.0016  lgb=4.0000\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in all_feature_importance:\n",
    "        continue\n",
    "    fi = all_feature_importance[DIST]\n",
    "    print(f\"\\n--- Feature Importance: {DIST} ---\")\n",
    "    for _, row in fi.iterrows():\n",
    "        print(f\"  {row['feature']:25s}  xgb={row['xgb_importance']:.4f}  lgb={row['lgb_importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c92a825",
   "metadata": {},
   "source": [
    "## 8. Stratified Evaluation (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd565d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  STRATIFIED EVAL: 70.3\n",
      "======================================================================\n",
      "  Stratified by Age Bracket:\n",
      "    18-29            n= 60,280  MAE=10.6min  MAPE=0.032\n",
      "    30-39            n= 82,124  MAE=12.3min  MAPE=0.036\n",
      "    40-49            n= 47,440  MAE=13.0min  MAPE=0.037\n",
      "    50-59            n= 12,980  MAE=15.0min  MAPE=0.042\n",
      "    60+              n=  1,774  MAE=19.3min  MAPE=0.049\n",
      "  Stratified by Finish Bracket:\n",
      "    5-6h             n= 86,873  MAE=10.2min  MAPE=0.031\n",
      "    6-7h             n= 60,388  MAE=11.4min  MAPE=0.029\n",
      "    7-8h             n= 20,019  MAE=15.4min  MAPE=0.035\n",
      "    8h+              n=  4,228  MAE=30.5min  MAPE=0.057\n",
      "    <5h              n= 33,090  MAE=14.5min  MAPE=0.056\n",
      "  Stratified by Experience:\n",
      "    1-2 races        n= 94,234  MAE=4.7min  MAPE=0.013\n",
      "    3-5 races        n= 54,263  MAE=16.5min  MAPE=0.047\n",
      "    5+ races         n= 56,099  MAE=20.6min  MAPE=0.062\n",
      "\n",
      "======================================================================\n",
      "  STRATIFIED EVAL: 140.6\n",
      "======================================================================\n",
      "  Stratified by Age Bracket:\n",
      "    18-29            n= 60,877  MAE=16.8min  MAPE=0.024\n",
      "    30-39            n= 98,556  MAE=20.0min  MAPE=0.029\n",
      "    40-49            n= 56,289  MAE=21.5min  MAPE=0.030\n",
      "    50-59            n= 13,363  MAE=23.8min  MAPE=0.031\n",
      "    60+              n=  1,379  MAE=27.7min  MAPE=0.034\n",
      "  Stratified by Finish Bracket:\n",
      "    10-12h           n= 91,516  MAE=18.0min  MAPE=0.027\n",
      "    12-14h           n= 80,587  MAE=18.7min  MAPE=0.024\n",
      "    14-16h           n= 33,557  MAE=21.7min  MAPE=0.024\n",
      "    16h+             n=  5,143  MAE=26.8min  MAPE=0.027\n",
      "    <10h             n= 19,661  MAE=27.4min  MAPE=0.055\n",
      "  Stratified by Experience:\n",
      "    1-2 races        n=120,595  MAE=7.2min  MAPE=0.010\n",
      "    3-5 races        n= 56,726  MAE=29.3min  MAPE=0.041\n",
      "    5+ races         n= 53,015  MAE=38.1min  MAPE=0.056\n"
     ]
    }
   ],
   "source": [
    "def stratified_eval(y_true, y_pred, groups, group_name):\n",
    "    print(f\"  Stratified by {group_name}:\")\n",
    "    # Filter out NaN values before sorting to avoid comparison errors\n",
    "    valid_groups = [g for g in groups.unique() if pd.notna(g)]\n",
    "    for g in sorted(valid_groups):\n",
    "        mask = groups == g\n",
    "        if mask.sum() < 50:\n",
    "            continue\n",
    "        mae = mean_absolute_error(y_true[mask], y_pred[mask])\n",
    "        mape = mean_absolute_percentage_error(y_true[mask], y_pred[mask])\n",
    "        print(f\"    {str(g):15s}  n={mask.sum():>7,}  MAE={mae/60:.1f}min  MAPE={mape:.3f}\")\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in all_predictions:\n",
    "        continue\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  STRATIFIED EVAL: {DIST}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    preds = all_predictions[DIST]\n",
    "    test_data = preds['test_df']\n",
    "    y_t = preds['y_test']\n",
    "    # Use tuned XGB if available, else regular XGB\n",
    "    pred_t = preds.get('pred_xgb_tuned', preds['pred_xgb'])\n",
    "\n",
    "    # By age bracket\n",
    "    age_brackets = pd.cut(test_data['age_band'].fillna(35).values, bins=[0, 30, 40, 50, 60, 100],\n",
    "                           labels=['18-29', '30-39', '40-49', '50-59', '60+'])\n",
    "    stratified_eval(y_t, pred_t, age_brackets, 'Age Bracket')\n",
    "\n",
    "    # By finish bracket\n",
    "    if DIST == '70.3':\n",
    "        bins = [0, 5, 6, 7, 8, 20]\n",
    "        labels = ['<5h', '5-6h', '6-7h', '7-8h', '8h+']\n",
    "    else:\n",
    "        bins = [0, 10, 12, 14, 16, 30]\n",
    "        labels = ['<10h', '10-12h', '12-14h', '14-16h', '16h+']\n",
    "    finish_brackets = pd.cut(y_t / 3600, bins=bins, labels=labels)\n",
    "    stratified_eval(y_t, pred_t, finish_brackets, 'Finish Bracket')\n",
    "\n",
    "    # By experience\n",
    "    exp = test_data['total_races'].fillna(0).values\n",
    "    exp_brackets = pd.cut(exp, bins=[-1, 0, 2, 5, 100],\n",
    "                           labels=['0 races', '1-2 races', '3-5 races', '5+ races'])\n",
    "    stratified_eval(y_t, pred_t, exp_brackets, 'Experience')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432a0cb",
   "metadata": {},
   "source": [
    "## 9. Cross-Distance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a05a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  CROSS-DISTANCE COMPARISON (test sets)\n",
      "======================================================================\n",
      "\n",
      "  70.3:\n",
      "    XGB_Tuned_test             MAE=12.2min  MAPE=0.035  R²=0.8574\n",
      "    XGB_test                   MAE=12.8min  MAPE=0.037  R²=0.8461\n",
      "    RF_test                    MAE=12.9min  MAPE=0.038  R²=0.8306\n",
      "    LGB_test                   MAE=13.5min  MAPE=0.039  R²=0.8363\n",
      "    CAT_test                   MAE=13.5min  MAPE=0.039  R²=0.8339\n",
      "    Chained_test               MAE=16.1min  MAPE=0.045  R²=0.8198\n",
      "    Ridge_test                 MAE=27.1min  MAPE=0.078  R²=0.5351\n",
      "\n",
      "  140.6:\n",
      "    XGB_Tuned_test             MAE=19.8min  MAPE=0.028  R²=0.8914\n",
      "    XGB_test                   MAE=20.7min  MAPE=0.029  R²=0.8862\n",
      "    RF_test                    MAE=21.7min  MAPE=0.031  R²=0.8669\n",
      "    LGB_test                   MAE=21.9min  MAPE=0.031  R²=0.8776\n",
      "    CAT_test                   MAE=22.0min  MAPE=0.031  R²=0.8775\n",
      "    Chained_test               MAE=27.0min  MAPE=0.037  R²=0.8655\n",
      "    Ridge_test                 MAE=45.3min  MAPE=0.064  R²=0.6669\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"  CROSS-DISTANCE COMPARISON (test sets)\")\n",
    "print(\"=\"*70)\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in all_results:\n",
    "        continue\n",
    "    print(f\"\\n  {DIST}:\")\n",
    "    test_results = {k: v for k, v in all_results[DIST].items() if 'test' in k.lower()}\n",
    "    for k, v in sorted(test_results.items(), key=lambda x: x[1]['MAE_sec']):\n",
    "        print(f\"    {k:25s}  MAE={v['MAE_min']:.1f}min  MAPE={v['MAPE']:.3f}  R²={v['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b912f4",
   "metadata": {},
   "source": [
    "## 10. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9808a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ⚠ Chained predictions length mismatch for 70.3: 196261 vs 204598\n",
      "    Saving chained predictions to separate file\n",
      "    model_predictions_70.3_chained.csv: 196,261 rows\n",
      "model_predictions_70.3.csv: 204,598 rows\n",
      "  ⚠ Chained predictions length mismatch for 140.6: 224412 vs 230464\n",
      "    Saving chained predictions to separate file\n",
      "    model_predictions_140.6_chained.csv: 224,412 rows\n",
      "model_predictions_140.6.csv: 230,464 rows\n",
      "feature_importance.csv: 26 rows\n",
      "supervised_results.csv: 26 rows\n",
      "\n",
      "✅ SUPERVISED LEARNING COMPLETE (per-distance models)\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in all_predictions:\n",
    "        continue\n",
    "    preds = all_predictions[DIST]\n",
    "    test_data = preds['test_df']\n",
    "\n",
    "    # Model predictions\n",
    "    pred_df = test_data[['athlete_hash', 'event_distance', 'event_year', 'total_sec']].copy()\n",
    "    pred_df['pred_xgb'] = preds['pred_xgb']\n",
    "    pred_df['pred_lgb'] = preds['pred_lgb']\n",
    "    pred_df['pred_cat'] = preds['pred_cat']\n",
    "    pred_df['pred_rf'] = preds['pred_rf']\n",
    "    pred_df['pred_ridge'] = preds['pred_ridge']\n",
    "    if 'pred_xgb_tuned' in preds:\n",
    "        pred_df['pred_xgb_tuned'] = preds['pred_xgb_tuned']\n",
    "    \n",
    "    # Chained predictions - check length before assigning\n",
    "    if 'pred_chained' in preds:\n",
    "        chained_len = len(preds['pred_chained'])\n",
    "        test_len = len(test_data)\n",
    "        \n",
    "        if chained_len == test_len:\n",
    "            # Lengths match - direct assignment\n",
    "            pred_df['pred_chained'] = preds['pred_chained']\n",
    "            pred_df['pred_swim'] = preds['pred_swim']\n",
    "            pred_df['pred_bike'] = preds['pred_bike']\n",
    "            pred_df['pred_run'] = preds['pred_run']\n",
    "        else:\n",
    "            # Lengths don't match - save chained predictions separately\n",
    "            print(f\"  ⚠ Chained predictions length mismatch for {DIST}: {chained_len} vs {test_len}\")\n",
    "            print(f\"    Saving chained predictions to separate file\")\n",
    "            \n",
    "            # Get the segment-complete test set\n",
    "            dist_df = df[(df['event_distance'] == DIST)].dropna(subset=SEGMENT_TARGETS + [TARGET])\n",
    "            _, _, test_chained = random_athlete_split(dist_df)\n",
    "            \n",
    "            chained_df = test_chained[['athlete_hash', 'event_distance', 'event_year', 'total_sec']].copy()\n",
    "            chained_df['pred_chained'] = preds['pred_chained']\n",
    "            chained_df['pred_swim'] = preds['pred_swim']\n",
    "            chained_df['pred_bike'] = preds['pred_bike']\n",
    "            chained_df['pred_run'] = preds['pred_run']\n",
    "            \n",
    "            chained_fname = f'model_predictions_{DIST}_chained.csv'\n",
    "            chained_df.to_csv(CLEANED / chained_fname, index=False)\n",
    "            print(f\"    {chained_fname}: {len(chained_df):,} rows\")\n",
    "\n",
    "    # Add quantiles\n",
    "    if DIST in all_quantile_preds:\n",
    "        for q in quantiles:\n",
    "            pred_df[f'q{int(q*100):02d}'] = all_quantile_preds[DIST][q]\n",
    "\n",
    "    fname = f'model_predictions_{DIST}.csv'\n",
    "    pred_df.to_csv(CLEANED / fname, index=False)\n",
    "    print(f\"{fname}: {len(pred_df):,} rows\")\n",
    "\n",
    "# Feature importance (combined)\n",
    "fi_all = []\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST in all_feature_importance:\n",
    "        fi = all_feature_importance[DIST].copy()\n",
    "        fi['distance'] = DIST\n",
    "        fi_all.append(fi)\n",
    "if fi_all:\n",
    "    fi_combined = pd.concat(fi_all)\n",
    "    fi_combined.to_csv(CLEANED / 'feature_importance.csv', index=False)\n",
    "    print(f\"feature_importance.csv: {len(fi_combined)} rows\")\n",
    "\n",
    "# Results summary\n",
    "rows = []\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in all_results:\n",
    "        continue\n",
    "    for model_name, metrics in all_results[DIST].items():\n",
    "        rows.append({'distance': DIST, 'model': model_name, **metrics})\n",
    "res_summary = pd.DataFrame(rows)\n",
    "res_summary.to_csv(CLEANED / 'supervised_results.csv', index=False)\n",
    "print(f\"supervised_results.csv: {len(res_summary)} rows\")\n",
    "\n",
    "print(\"\\n✅ SUPERVISED LEARNING COMPLETE (per-distance models)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939f684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
