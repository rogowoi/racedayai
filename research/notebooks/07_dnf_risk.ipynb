{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d88b6fb",
   "metadata": {},
   "source": [
    "# Notebook 07 — DNF Risk Classifier (Per-Distance)\n",
    "**RaceDayAI ML Prediction Engine (Plan 07)**\n",
    "\n",
    "Per-distance binary classification: finisher vs DNF/DNS/DQ. DNF rates and risk factors differ\n",
    "significantly between 70.3 and 140.6 — separate models capture these differences.\n",
    "LightGBM with class imbalance handling, SHAP explainability, calibration curves.\n",
    "\n",
    "**Reads:** `athlete_race.csv`, `athlete_profile.csv`, `cluster_assignments.csv`\n",
    "**Writes:** `dnf_model_predictions_70.3.csv`, `dnf_model_predictions_140.6.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8681a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score,\n",
    "                             precision_recall_curve, roc_curve,\n",
    "                             classification_report, brier_score_loss)\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE = Path('.').resolve().parent\n",
    "CLEANED = BASE / 'data' / 'cleaned'\n",
    "\n",
    "MODEL_DISTANCES = ['70.3', '140.6']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a610358d",
   "metadata": {},
   "source": [
    "## 1. Load Data & Define DNF Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23082391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  70.3: 0 records, DNF/DNS/DQ: 0 (0.00%)\n",
      "  140.6: 851,360 records, DNF/DNS/DQ: 745 (0.09%)\n",
      "Total: 851,360\n"
     ]
    }
   ],
   "source": [
    "races = pd.read_csv(CLEANED / 'athlete_race.csv', low_memory=False)\n",
    "profiles = pd.read_csv(CLEANED / 'athlete_profile.csv', low_memory=False)\n",
    "clusters = pd.read_csv(CLEANED / 'cluster_assignments.csv', low_memory=False)\n",
    "\n",
    "# DNF target comes from CoachCox finish_status field\n",
    "# Only CoachCox has reliable DNF data\n",
    "df = races[races['source'] == 'coachcox'].copy() if 'source' in races.columns else races.copy()\n",
    "\n",
    "# Define target\n",
    "if 'finish_status' in df.columns:\n",
    "    df['is_dnf'] = df['finish_status'].fillna('finisher').str.upper().isin(['DNF', 'DNS', 'DQ']).astype(int)\n",
    "else:\n",
    "    df['is_dnf'] = df['total_sec'].isna().astype(int)\n",
    "\n",
    "# Filter to AG\n",
    "df = df[df['is_pro'] != True].copy()\n",
    "\n",
    "# Merge profiles\n",
    "pcols = ['athlete_hash', 'total_races', 'pb_total_sec', 'consistency_cv',\n",
    "         'improvement_slope', 'dnf_rate', 'dnf_count',\n",
    "         'swim_strength_z', 'bike_strength_z', 'run_strength_z']\n",
    "pcols = [c for c in pcols if c in profiles.columns]\n",
    "df = df.merge(profiles[pcols], on='athlete_hash', how='left')\n",
    "\n",
    "# Merge clusters\n",
    "ccols = ['athlete_hash', 'cluster_id']\n",
    "ccols = [c for c in ccols if c in clusters.columns]\n",
    "df = df.merge(clusters[ccols], on='athlete_hash', how='left')\n",
    "\n",
    "# Per-distance summary\n",
    "for d in MODEL_DISTANCES:\n",
    "    mask = df['event_distance'] == d\n",
    "    n = mask.sum()\n",
    "    dnf_n = df.loc[mask, 'is_dnf'].sum()\n",
    "    print(f\"  {d}: {n:,} records, DNF/DNS/DQ: {dnf_n:,} ({100*dnf_n/max(n,1):.2f}%)\")\n",
    "print(f\"Total: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b19e26",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3c230e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 13\n",
      "  ['gender_enc', 'age_band', 'year', 'total_races', 'pb_total_sec', 'swim_strength_z', 'bike_strength_z', 'run_strength_z', 'improvement_slope', 'consistency_cv', 'cluster_id', 'athlete_dnf_rate', 'athlete_dnf_count']\n"
     ]
    }
   ],
   "source": [
    "# Gender\n",
    "le_g = LabelEncoder()\n",
    "df['gender_enc'] = le_g.fit_transform(df['gender'].fillna('M'))\n",
    "\n",
    "# Age band\n",
    "df['age_band'] = pd.to_numeric(df['age_group'].str.extract(r'(\\d+)', expand=False), errors='coerce')\n",
    "\n",
    "# Year\n",
    "df['year'] = pd.to_numeric(df['event_year'], errors='coerce')\n",
    "\n",
    "# Cluster\n",
    "df['cluster_id'] = df['cluster_id'].fillna(-1).astype(int)\n",
    "\n",
    "# Historical DNF rate\n",
    "df['athlete_dnf_rate'] = df['dnf_rate'].fillna(0)\n",
    "df['athlete_dnf_count'] = df['dnf_count'].fillna(0) if 'dnf_count' in df.columns else 0\n",
    "\n",
    "# Features (no distance — we train separate models)\n",
    "FEATURES = [\n",
    "    'gender_enc', 'age_band', 'year',\n",
    "    'total_races', 'pb_total_sec',\n",
    "    'swim_strength_z', 'bike_strength_z', 'run_strength_z',\n",
    "    'improvement_slope', 'consistency_cv',\n",
    "    'cluster_id',\n",
    "    'athlete_dnf_rate', 'athlete_dnf_count',\n",
    "]\n",
    "FEATURES = [f for f in FEATURES if f in df.columns]\n",
    "\n",
    "# Fill NaN\n",
    "for col in FEATURES:\n",
    "    if df[col].isna().any():\n",
    "        df[col] = df[col].fillna(df[col].median() if df[col].dtype != 'object' else 0)\n",
    "\n",
    "TARGET = 'is_dnf'\n",
    "print(f\"Features: {len(FEATURES)}\")\n",
    "print(f\"  {FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335e97d",
   "metadata": {},
   "source": [
    "## 3. Per-Distance Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e22ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  DNF CLASSIFIER: 70.3\n",
      "======================================================================\n",
      "  ⚠ Insufficient data for 70.3\n",
      "\n",
      "======================================================================\n",
      "  DNF CLASSIFIER: 140.6\n",
      "======================================================================\n",
      "  Records: 851,360\n",
      "  DNF rate: 0.0009 (745 DNFs)\n",
      "  train: 596,126 (DNF: 517, rate: 0.0009)\n",
      "  val  : 127,343 (DNF: 116, rate: 0.0009)\n",
      "  test : 127,891 (DNF: 112, rate: 0.0009)\n",
      "  Class imbalance: 1:1152.0\n",
      "[100]\tvalid_0's binary_logloss: 19.7458\n",
      "[200]\tvalid_0's binary_logloss: 19.7458\n",
      "[300]\tvalid_0's binary_logloss: 19.7458\n",
      "[400]\tvalid_0's binary_logloss: 19.7458\n",
      "[500]\tvalid_0's binary_logloss: 19.7458\n",
      "\n",
      "  Validation: AUC=0.7139  AP=0.0016\n",
      "  Test:       AUC=0.7130  AP=0.0015  Brier=0.5736\n"
     ]
    }
   ],
   "source": [
    "dnf_results = {}\n",
    "\n",
    "for DIST in MODEL_DISTANCES:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  DNF CLASSIFIER: {DIST}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    dist_df = df[df['event_distance'] == DIST].copy()\n",
    "    if len(dist_df) < 500:\n",
    "        print(f\"  ⚠ Insufficient data for {DIST}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"  Records: {len(dist_df):,}\")\n",
    "    print(f\"  DNF rate: {dist_df['is_dnf'].mean():.4f} ({dist_df['is_dnf'].sum():,} DNFs)\")\n",
    "\n",
    "    # Random split (grouped by athlete to prevent leakage)\n",
    "    athletes = dist_df['athlete_hash'].unique()\n",
    "    rng = np.random.RandomState(42)\n",
    "    rng.shuffle(athletes)\n",
    "    n = len(athletes)\n",
    "    n_train = int(0.70 * n)\n",
    "    n_val = int(0.15 * n)\n",
    "    train_ath = set(athletes[:n_train])\n",
    "    val_ath = set(athletes[n_train:n_train + n_val])\n",
    "    test_ath = set(athletes[n_train + n_val:])\n",
    "    train = dist_df[dist_df['athlete_hash'].isin(train_ath)].copy()\n",
    "    val = dist_df[dist_df['athlete_hash'].isin(val_ath)].copy()\n",
    "    test = dist_df[dist_df['athlete_hash'].isin(test_ath)].copy()\n",
    "\n",
    "    # Skip if not enough data in any split\n",
    "    for name, split_df in [('train', train), ('val', val), ('test', test)]:\n",
    "        dnf_n = split_df['is_dnf'].sum()\n",
    "        print(f\"  {name:5s}: {len(split_df):,} (DNF: {dnf_n:,}, rate: {split_df['is_dnf'].mean():.4f})\")\n",
    "        if dnf_n < 10:\n",
    "            print(f\"  ⚠ Too few DNFs in {name} split\")\n",
    "\n",
    "    X_train = train[FEATURES].values\n",
    "    y_train = train[TARGET].values\n",
    "    X_val = val[FEATURES].values\n",
    "    y_val = val[TARGET].values\n",
    "    X_test = test[FEATURES].values\n",
    "    y_test = test[TARGET].values\n",
    "\n",
    "    # Class weight\n",
    "    n_pos = y_train.sum()\n",
    "    n_neg = len(y_train) - n_pos\n",
    "    scale_pos_weight = n_neg / max(n_pos, 1)\n",
    "    print(f\"  Class imbalance: 1:{scale_pos_weight:.1f}\")\n",
    "\n",
    "    # Train LightGBM\n",
    "    lgb_dnf = lgb.LGBMClassifier(\n",
    "        n_estimators=500, max_depth=6, learning_rate=0.05,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        min_child_samples=50,\n",
    "        random_state=42, n_jobs=-1, verbose=-1,\n",
    "    )\n",
    "    lgb_dnf.fit(X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                callbacks=[lgb.log_evaluation(100)])\n",
    "\n",
    "    # Predict\n",
    "    prob_val = lgb_dnf.predict_proba(X_val)[:, 1]\n",
    "    prob_test = lgb_dnf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    if y_val.sum() > 0:\n",
    "        auc_val = roc_auc_score(y_val, prob_val)\n",
    "        ap_val = average_precision_score(y_val, prob_val)\n",
    "        print(f\"\\n  Validation: AUC={auc_val:.4f}  AP={ap_val:.4f}\")\n",
    "\n",
    "    if y_test.sum() > 0:\n",
    "        auc_test = roc_auc_score(y_test, prob_test)\n",
    "        ap_test = average_precision_score(y_test, prob_test)\n",
    "        brier_test = brier_score_loss(y_test, prob_test)\n",
    "        print(f\"  Test:       AUC={auc_test:.4f}  AP={ap_test:.4f}  Brier={brier_test:.4f}\")\n",
    "\n",
    "    dnf_results[DIST] = {\n",
    "        'model': lgb_dnf,\n",
    "        'dist_df': dist_df,\n",
    "        'test': test,\n",
    "        'y_test': y_test,\n",
    "        'prob_test': prob_test,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583122ef",
   "metadata": {},
   "source": [
    "## 4. Threshold Selection (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0950fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Threshold: 140.6 ---\n",
      "  Best F1 threshold: 1.000 (F1=0.003)\n",
      "  Elevated risk: >0.500\n",
      "  High risk:     >1.000\n",
      "\n",
      "  Classification report (threshold=1.000):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Finisher       1.00      0.43      0.60    127779\n",
      "         DNF       0.00      1.00      0.00       112\n",
      "\n",
      "    accuracy                           0.43    127891\n",
      "   macro avg       0.50      0.71      0.30    127891\n",
      "weighted avg       1.00      0.43      0.60    127891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in dnf_results:\n",
    "        continue\n",
    "    print(f\"\\n--- Threshold: {DIST} ---\")\n",
    "\n",
    "    r = dnf_results[DIST]\n",
    "    y_test = r['y_test']\n",
    "    prob_test = r['prob_test']\n",
    "\n",
    "    if y_test.sum() == 0:\n",
    "        print(\"  No DNFs in test set — skipping threshold selection\")\n",
    "        continue\n",
    "\n",
    "    precision_arr, recall_arr, thresholds = precision_recall_curve(y_test, prob_test)\n",
    "    f1_scores = 2 * precision_arr * recall_arr / (precision_arr + recall_arr + 1e-8)\n",
    "    best_f1_idx = np.argmax(f1_scores)\n",
    "    best_threshold = thresholds[min(best_f1_idx, len(thresholds)-1)]\n",
    "    print(f\"  Best F1 threshold: {best_threshold:.3f} (F1={f1_scores[best_f1_idx]:.3f})\")\n",
    "\n",
    "    THRESHOLD_ELEVATED = best_threshold * 0.5\n",
    "    THRESHOLD_HIGH = best_threshold\n",
    "    print(f\"  Elevated risk: >{THRESHOLD_ELEVATED:.3f}\")\n",
    "    print(f\"  High risk:     >{THRESHOLD_HIGH:.3f}\")\n",
    "\n",
    "    pred_labels = (prob_test >= THRESHOLD_HIGH).astype(int)\n",
    "    print(f\"\\n  Classification report (threshold={THRESHOLD_HIGH:.3f}):\")\n",
    "    print(classification_report(y_test, pred_labels, target_names=['Finisher', 'DNF']))\n",
    "\n",
    "    r['threshold_elevated'] = THRESHOLD_ELEVATED\n",
    "    r['threshold_high'] = THRESHOLD_HIGH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef651b",
   "metadata": {},
   "source": [
    "## 5. Calibration Analysis (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ba5027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calibration: 140.6 ---\n",
      "  Predicted: 0.000  Actual: 0.000  ✓\n",
      "  Predicted: 1.000  Actual: 0.002  ✗\n",
      "  Saved dnf_curves_1406.png\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in dnf_results:\n",
    "        continue\n",
    "    r = dnf_results[DIST]\n",
    "    y_test = r['y_test']\n",
    "    prob_test = r['prob_test']\n",
    "\n",
    "    if y_test.sum() < 10:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- Calibration: {DIST} ---\")\n",
    "    prob_true, prob_pred = calibration_curve(y_test, prob_test, n_bins=10, strategy='quantile')\n",
    "    for pt, pp in zip(prob_true, prob_pred):\n",
    "        status = '✓' if abs(pt - pp) < 0.02 else '~' if abs(pt - pp) < 0.05 else '✗'\n",
    "        print(f\"  Predicted: {pp:.3f}  Actual: {pt:.3f}  {status}\")\n",
    "\n",
    "    # Plot\n",
    "    try:\n",
    "        import matplotlib\n",
    "        matplotlib.use('Agg')\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_test, prob_test)\n",
    "        auc_val = roc_auc_score(y_test, prob_test)\n",
    "        axes[0].plot(fpr, tpr, 'b-', label=f'LightGBM (AUC={auc_val:.3f})')\n",
    "        axes[0].plot([0,1], [0,1], 'k--', alpha=0.3)\n",
    "        axes[0].set_xlabel('False Positive Rate')\n",
    "        axes[0].set_ylabel('True Positive Rate')\n",
    "        axes[0].set_title(f'ROC Curve — DNF Risk ({DIST})')\n",
    "        axes[0].legend()\n",
    "\n",
    "        axes[1].plot(prob_pred, prob_true, 'bo-', label='LightGBM')\n",
    "        axes[1].plot([0,1], [0,1], 'k--', alpha=0.3, label='Perfect')\n",
    "        axes[1].set_xlabel('Predicted Probability')\n",
    "        axes[1].set_ylabel('Actual Probability')\n",
    "        axes[1].set_title(f'Calibration Curve ({DIST})')\n",
    "        axes[1].legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fname = f'dnf_curves_{DIST.replace(\".\", \"\")}.png'\n",
    "        plt.savefig(CLEANED / fname, dpi=150)\n",
    "        plt.show()\n",
    "        print(f\"  Saved {fname}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Plotting failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd391424",
   "metadata": {},
   "source": [
    "## 6. SHAP Feature Importance (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b780cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SHAP: 140.6 ---\n",
      "  SHAP Feature Importance (140.6):\n",
      "    year                     : 570222.8421\n",
      "    pb_total_sec             : 46909.2735\n",
      "    swim_strength_z          : 22768.4768\n",
      "    total_races              : 18953.4738\n",
      "    run_strength_z           : 6017.8229\n",
      "    cluster_id               : 4402.8699\n",
      "    consistency_cv           : 3788.1863\n",
      "    bike_strength_z          : 3600.0411\n",
      "    age_band                 : 1979.4368\n",
      "    athlete_dnf_count        : 354.8794\n",
      "    improvement_slope        : 106.2365\n",
      "    athlete_dnf_rate         : 0.2673\n",
      "    gender_enc               : 0.0069\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in dnf_results:\n",
    "        continue\n",
    "    print(f\"\\n--- SHAP: {DIST} ---\")\n",
    "    r = dnf_results[DIST]\n",
    "    lgb_dnf = r['model']\n",
    "    X_test = r['test'][FEATURES].values\n",
    "\n",
    "    try:\n",
    "        import shap\n",
    "        explainer = shap.TreeExplainer(lgb_dnf)\n",
    "        n_shap = min(5000, len(X_test))\n",
    "        shap_values = explainer.shap_values(X_test[:n_shap])\n",
    "\n",
    "        if isinstance(shap_values, list):\n",
    "            shap_vals = shap_values[1]\n",
    "        else:\n",
    "            shap_vals = shap_values\n",
    "\n",
    "        mean_abs_shap = np.abs(shap_vals).mean(axis=0)\n",
    "        fi_shap = pd.DataFrame({'feature': FEATURES, 'mean_abs_shap': mean_abs_shap})\n",
    "        fi_shap = fi_shap.sort_values('mean_abs_shap', ascending=False)\n",
    "        print(f\"  SHAP Feature Importance ({DIST}):\")\n",
    "        for _, row in fi_shap.iterrows():\n",
    "            print(f\"    {row['feature']:25s}: {row['mean_abs_shap']:.4f}\")\n",
    "\n",
    "    except ImportError:\n",
    "        print(\"  SHAP not installed — using LightGBM native importance\")\n",
    "        fi_lgb = pd.DataFrame({'feature': FEATURES, 'importance': lgb_dnf.feature_importances_})\n",
    "        fi_lgb = fi_lgb.sort_values('importance', ascending=False)\n",
    "        for _, row in fi_lgb.iterrows():\n",
    "            print(f\"    {row['feature']:25s}: {row['importance']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e507254",
   "metadata": {},
   "source": [
    "## 7. Save Outputs (Per Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "236fcce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving 140.6 ---\n",
      "  dnf_model_predictions_140.6.csv: 851,360\n",
      "    Low:      364,479\n",
      "    Elevated: 486,881\n",
      "    High:     0\n",
      "\n",
      "✅ DNF RISK CLASSIFIER COMPLETE (per-distance)\n"
     ]
    }
   ],
   "source": [
    "for DIST in MODEL_DISTANCES:\n",
    "    if DIST not in dnf_results:\n",
    "        continue\n",
    "    print(f\"\\n--- Saving {DIST} ---\")\n",
    "\n",
    "    r = dnf_results[DIST]\n",
    "    lgb_dnf = r['model']\n",
    "    dist_df = r['dist_df']\n",
    "    THRESHOLD_ELEVATED = r.get('threshold_elevated', 0.05)\n",
    "    THRESHOLD_HIGH = r.get('threshold_high', 0.10)\n",
    "\n",
    "    # Full dataset predictions\n",
    "    X_all = dist_df[FEATURES].values\n",
    "    dist_df = dist_df.copy()\n",
    "    dist_df['dnf_prob'] = lgb_dnf.predict_proba(X_all)[:, 1]\n",
    "    dist_df['dnf_risk_level'] = 'low'\n",
    "    dist_df.loc[dist_df['dnf_prob'] > THRESHOLD_ELEVATED, 'dnf_risk_level'] = 'elevated'\n",
    "    dist_df.loc[dist_df['dnf_prob'] > THRESHOLD_HIGH, 'dnf_risk_level'] = 'high'\n",
    "\n",
    "    out = dist_df[['athlete_hash', 'event_distance', 'event_year',\n",
    "                    'is_dnf', 'dnf_prob', 'dnf_risk_level']].copy()\n",
    "    fname = f'dnf_model_predictions_{DIST}.csv'\n",
    "    out.to_csv(CLEANED / fname, index=False)\n",
    "    print(f\"  {fname}: {len(out):,}\")\n",
    "    print(f\"    Low:      {(out['dnf_risk_level']=='low').sum():,}\")\n",
    "    print(f\"    Elevated: {(out['dnf_risk_level']=='elevated').sum():,}\")\n",
    "    print(f\"    High:     {(out['dnf_risk_level']=='high').sum():,}\")\n",
    "\n",
    "print(\"\\n✅ DNF RISK CLASSIFIER COMPLETE (per-distance)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
